
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="VTGaussian-SLAM: RGBD SLAM for Large Scale Scenes with Splatting View-Tied 3D Gaussians.">
  <meta name="keywords" content="VTGaussian-SLAM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VTGaussian-SLAM</title>
  <link rel="stylesheet" href="./style.css">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!-- <script type="text/javascript" src="./gb3d_bundle.js"></script> -->
  
</head>
<body>

<!-- 
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://junshengzhou.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/junshengzhou/3DAttriFlow">
            3DAttriFlow
          </a>
          <a class="navbar-item" href="https://junshengzhou.github.io/3D-OAE">
            3D Occlusion Auto-Encoder
          </a>
          <a class="navbar-item" href="https://github.com/mabaorui/NeuralPull-Pytorch">
            Neural-Pull
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>
-->


<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://pengchongh.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://machineperceptionlab.github.io/VTGaussian-SLAM-Project">
            VTGaussian-SLAM
          </a>
          <a class="navbar-item" href="https://machineperceptionlab.github.io/Attentive_DF_Prior">
            Attentive_DFPrior
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">VTGaussian-SLAM: RGBD SLAM for Large Scale Scenes with Splatting View-Tied 3D Gaussians</h1>
          <div class="column is-full_width">
            <h2 class="title is-4">ICML 2025</h2>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://pengchongh.github.io/">Pengchong Hu</a><sup></sup>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://h312h.github.io/">Zhizhong Han</a><sup></sup>
            </span>
          </div>
          <!-- <div class="column is-full_width">
            <h2 class="is-size-6">* Equal Contribution</h2> -->
            <!-- <h2 class="is-size-6">(* equal contribution)  (<span>&#8224;</span> corresponding author)</h2> -->
          <!-- </div> -->
          <!--<div class="is-size-5 publication-authors" class="row"> <p class="affiliation">Machine Perception Lab</p> </div>
                        <div class="is-size-5 publication-authors" class="row"> <p class="affiliation">Wayne State University</p> </div>
                        <div class="is-size-5 publication-authors" class="row"> <p class="affiliation">Detroit, USA</p> </div> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup></sup>Machine Perception Lab, Wayne State University, Detroit, USA</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2506.02741"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/MachinePerceptionLab/VTGaussian-SLAM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Demo</h2>

        <video width="800"  poster="" id="Video" autoplay controls muted loop playsinline height="10%">
          <source src="./videos/video_gs_center.mp4"
                  type="video/mp4">
        </video>
        <div class="content has-text-justified">
          <p align="center">
            Visualization of Gaussian centers from an RGBD sequence.
          </p>

        </div>
        <div class="content has-text-justified">
          <p align="center" style="font-size:12px;">
            (The blue in attention visualization indicates the attention mechanism pays more attention on depth fusion priors.)
          </p>

        </div>
      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Jointly estimating camera poses and mapping scenes from RGBD images is a fundamental task in simultaneous localization and mapping (SLAM). 
            State-of-the-art methods employ 3D Gaussians to represent a scene, and render these Gaussians through splatting for higher efficiency and better rendering. 
            However, these methods cannot scale up to extremely large scenes, due to the inefficient tracking and mapping strategies that need to optimize all 3D Gaussians in the limited GPU memories throughout the training to maintain the geometry and color consistency to previous RGBD observations. 
            To resolve this issue, we propose novel tracking and mapping strategies to work with a novel 3D representation, dubbed view-tied 3D Gaussians, for RGBD SLAM systems. 
            View-tied 3D Gaussians is a kind of simplified Gaussians, which is tied to depth pixels, without needing to learn locations, rotations, and multi-dimensional variances. 
            Tying Gaussians to views not only significantly saves storage but also allows us to employ many more Gaussians to represent local details in the limited GPU memory. 
            Moreover, our strategies remove the need of maintaining all Gaussians learnable throughout the training, while improving rendering quality, and tracking accuracy. 
            We justify the effectiveness of these designs, and report better performance over the latest methods on the widely used benchmarks in terms of rendering and tracking accuracy and scalability.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Method</h2>

        <img src="./images/OverviewGSSLAM_mod.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>Overview of our method.</b> We organize view-tied 3D Gaussians from several consecutive frames as a section so that we can keep as many Gaussians
            as the GPU memory allows to represent a local area, access these Gaussians more efficiently, and more importantly, enable more robust completion of missing depth by utilizing neighboring frames’ depth. 
            In each section, we mark the first frame as a head to differentiate it from regular frames for different Gaussian initialization strategies in mapping. 
            For tracking the latest frame, we select Gaussians in a section, render them from the camera pose initialized by the constant speed assumption, and optimize the pose by minimizing rendering errors to the latest frame. 
            If the latest frame is the head of a new section, as shown in (a), we select the Gaussians in a certain section in front according to the visibility. 
            If the latest frame is not a head but a regular frame in the current section, as shown in (c), we select the Gaussians in this section for renderings with higher quality. 
            For mapping the scene using the latest frame, if the latest frame is the head of a new section, as shown in (b), we initialize Gaussians by centering them at all pixels with valid depth values. 
            If the latest frame is not a head but a regular frame in an existing section, as shown in (d), we only initialize Gaussians as a complement in areas where pixels have valid depth values and the existing Gaussians in the current section cannot cover.
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Video</h2>

        <video width="680" poster="" id="Video" autoplay controls muted loop playsinline height="10%">
          <source src="./videos/VTGaussianSLAM.mp4" type="video/mp4">
        </video>
        <div class="content has-text-justified">
          <p>

          </p>

        </div>
      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>
<!-- <h2 class="subtitle has-text-centered">
  <strong>CAP-UDF</strong> learns a continuous UDF to represent shapes with arbitary architecture.
</h2> -->



<style>

  .box .left{
      width:480px;
      position:absolute;
     
  }

  .box .right{
      width:480px;
      position:absolute;

  }
  </style>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -20px">Experimental Results</h2>
        <div class="content has-text-justified">
          <p align="center" style="font-size:12px;">
            (Red in error maps indicates large errors.)
          </p>

        </div>
        <h3 class="title is-4">Replica Dataset</h3>
        <h4 class="title is-4 has-text-centered">NICE-SLAM &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
          &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  Ours</h4>
          <div style="float: left;">
          <video width="480"  poster="" id="Video" autoplay controls muted loop playsinline height="10%">
            <source src="./videos/nice_replica.mov"
                    type="video/mp4">
          </video></div><div style="float: right;">
          <video width="480"  poster="" id="Video" autoplay controls muted loop playsinline height="10%" >
            <source src="./videos/our_replica.mp4"
                    type="video/mp4">
          </video></div>
        <h3 class="title is-4">ScanNet Dataset</h3>
        <h4 class="title is-4 has-text-centered">NICE-SLAM &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
          &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  Ours</h4>
          <div style="float: left;">
            <video width="480"  poster="" id="Video" autoplay controls muted loop playsinline height="10%">
              <source src="./videos/nice_scannet.mov"
                      type="video/mp4">
            </video></div><div style="float: right;">
            <video width="480"  poster="" id="Video" autoplay controls muted loop playsinline height="10%" >
              <source src="./videos/our_scannet.mp4"
                      type="video/mp4">
            </video></div>
            

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>





<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{Hu2023LNI-ADFP,
      title = {Learning Neural Implicit through Volume Rendering with Attentive Depth Fusion Priors},
      author = {Hu, Pengchong and Han, Zhizhong},
      booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
      year = {2023}
    }
  </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This webpage template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

</body>
</html>
